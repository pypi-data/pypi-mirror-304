{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathiasleys/projects/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Communicator type:  <class 'curl.communicator.distributed_communicator.DistributedCommunicator'>\n",
      "[<>] Waiting for connections...\n",
      "[<>] DEFAULT ARGS: {'DISTRIBUTED_BACKEND': 'gloo', 'RENDEZVOUS': 'file:///tmp/vcrypten-Bcrypten-Zcrypten-gcrypten-Ecrypten-Gcrypten-xcrypten-gcrypten-mcrypten-l', 'WORLD_SIZE': 1, 'RANK': 0, 'TTP': False}\n",
      "[Device] LUTs initialized for cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import curl\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "curl.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"iiiorg/piiranha-v1-detect-personal-information\"\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: think could also have a different name like `n_embd` in the config, depending on the model\n",
    "hidden_size = model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ensure a constant input size, we will always pad or truncate to a fixed size\n",
    "INPUT_TEXT = \"this is a sentence\"\n",
    "\n",
    "encoded_input = tokenizer(\n",
    "    INPUT_TEXT,\n",
    "    return_tensors='pt',\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=hidden_size,\n",
    ")\n",
    "\n",
    "output = model.forward(\n",
    "    input_ids=encoded_input[\"input_ids\"],\n",
    "    attention_mask=encoded_input[\"attention_mask\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768, 18])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape: batch_size x num tokens x num classes\n",
    "# interpretation: probability logit for every class per token per sequence in the batch\n",
    "output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions are:  tensor([[17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17]])\n"
     ]
    }
   ],
   "source": [
    "predicted_classes = torch.argmax(output.logits, dim=-1)\n",
    "print(\"Predictions are: \", predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathiasleys/projects/.venv/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:547: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.tensor(mid - 1).type_as(relative_pos),\n",
      "/Users/mathiasleys/projects/.venv/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:551: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.ceil(torch.log(abs_pos / mid) / torch.log(torch.tensor((max_position - 1) / mid)) * (mid - 1)) + mid\n",
      "/Users/mathiasleys/projects/.venv/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:710: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  scale = torch.sqrt(torch.tensor(query_layer.size(-1), dtype=torch.float) * scale_factor)\n",
      "/Users/mathiasleys/projects/.venv/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:710: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scale = torch.sqrt(torch.tensor(query_layer.size(-1), dtype=torch.float) * scale_factor)\n",
      "/Users/mathiasleys/projects/.venv/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:785: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  scale = torch.sqrt(torch.tensor(pos_key_layer.size(-1), dtype=torch.float) * scale_factor)\n",
      "/Users/mathiasleys/projects/.venv/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:785: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scale = torch.sqrt(torch.tensor(pos_key_layer.size(-1), dtype=torch.float) * scale_factor)\n",
      "/Users/mathiasleys/projects/.venv/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:797: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  scale = torch.sqrt(torch.tensor(pos_query_layer.size(-1), dtype=torch.float) * scale_factor)\n",
      "/Users/mathiasleys/projects/.venv/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:797: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scale = torch.sqrt(torch.tensor(pos_query_layer.size(-1), dtype=torch.float) * scale_factor)\n",
      "/Users/mathiasleys/projects/.venv/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:798: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if key_layer.size(-2) != query_layer.size(-2):\n",
      "/Users/mathiasleys/projects/.venv/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:105: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  output = input.masked_fill(rmask, torch.tensor(torch.finfo(input.dtype).min))\n",
      "/Users/mathiasleys/projects/aivm-curl/curl/nn/onnx_converter.py:176: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:212.)\n",
      "  param = torch.from_numpy(numpy_helper.to_array(node))\n"
     ]
    }
   ],
   "source": [
    "private_model = curl.nn.from_pytorch(model, encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph encrypted module"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "private_model.encrypt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_input = curl.cryptensor(encoded_input[\"input_ids\"], precision=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathiasleys/projects/aivm-curl/curl/__init__.py:472: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Copy.cpp:305.)\n",
      "  condition = condition.float()\n"
     ]
    }
   ],
   "source": [
    "private_output = private_model.forward(private_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions are:  tensor([[ 1,  4, 11, 15,  4,  9,  6, 15,  9,  7,  8, 14,  4,  4, 12, 17,  1,  0,\n",
      "          3, 17, 17,  9,  9,  1, 10,  6,  1, 16,  8,  0,  3, 15,  4,  1, 14, 11,\n",
      "          0, 17,  9,  3, 17, 10, 13,  9, 17, 10,  8, 11, 10,  1,  6, 11,  0,  4,\n",
      "         11,  5,  1, 14,  2, 10, 14, 17,  7,  0, 16, 12,  8,  7,  4,  1, 15,  9,\n",
      "          7,  5,  3, 14,  9, 14, 15, 15,  9, 13, 11,  5,  5,  6, 15,  6,  9, 15,\n",
      "         11,  3,  1, 16,  1, 15,  9,  1, 15, 14, 10, 16,  9,  3,  1, 15,  1, 10,\n",
      "         16,  4,  4, 17, 12,  3, 12, 10, 14, 14,  1, 16, 10,  2,  3, 14,  4,  7,\n",
      "          7,  4, 10,  1, 13,  1,  6,  0,  9,  6,  3, 14,  1, 14, 10, 16,  1, 17,\n",
      "          3,  7, 15, 14, 12,  7,  1, 13, 14, 10, 14, 12, 15,  3,  1,  2,  5, 15,\n",
      "         14, 15,  6,  6, 11,  0,  1,  5,  9, 10, 13, 15, 15,  1,  5, 15,  4,  4,\n",
      "         15,  7,  9, 15,  1,  8,  6,  4,  1,  1,  9,  9, 15, 15, 15,  5,  5,  4,\n",
      "         12, 17, 12, 13, 10,  6,  6,  0,  2,  0,  9,  4, 15, 12,  5,  5, 12,  7,\n",
      "         13,  4,  3,  3,  3, 15, 11,  1,  9,  1, 16, 14,  4,  9,  7, 15, 15,  1,\n",
      "          9,  5,  9, 14, 17, 11, 16,  4,  9, 17, 12, 16,  5,  1,  4,  4,  3,  6,\n",
      "          5, 10, 12, 15,  0,  2, 16, 12, 12, 13,  6, 17,  1, 11, 16,  7, 11, 15,\n",
      "          6, 14,  6, 16,  9, 12, 16,  1,  4, 17, 10,  6,  8,  0,  4, 13,  0, 12,\n",
      "          5, 12, 10, 15,  2,  8,  8,  1, 13,  0, 10,  9,  4, 15,  2, 15, 14,  1,\n",
      "          9,  6, 15, 12, 11, 13, 17, 13,  8,  3, 11,  0, 17,  9, 15,  7,  5, 13,\n",
      "          1, 14,  2, 14,  1,  6,  6, 15,  7,  7,  1, 16,  0, 14, 12, 14,  6,  3,\n",
      "          3,  7,  7,  1, 14, 15,  8,  2, 12,  9, 15,  1,  1,  7,  0, 15, 17, 15,\n",
      "          1, 14,  9,  0,  9,  9,  1,  6, 12,  5, 11,  6,  4, 17,  5, 15, 10,  9,\n",
      "         10,  2,  6, 14,  1, 16,  2, 16,  9,  6,  1,  9, 14, 16,  9,  1,  9, 17,\n",
      "         14, 10, 15, 14,  9,  3, 16, 17, 17, 15,  8,  9, 17,  4,  0,  7,  2, 10,\n",
      "          1, 13, 12,  1,  7,  9,  1, 13,  3, 14,  9,  8, 15, 14,  1, 15,  9,  0,\n",
      "         12,  1,  2, 12, 15,  1,  3, 14,  7, 13, 16,  9,  2, 10,  7, 15, 12,  1,\n",
      "          8, 12,  9, 16, 14, 13,  4, 17, 16, 13,  6,  8, 11, 17, 15, 11, 13,  1,\n",
      "          9,  2,  2, 10,  6,  4, 17,  9, 10,  9,  4,  1, 13, 11, 14,  7,  5,  3,\n",
      "          2,  5,  5,  1,  1,  5, 14,  3, 17,  0,  8, 13,  1, 14, 13, 16, 15, 13,\n",
      "          6,  0,  9, 14,  6,  4, 12, 16,  1,  1,  4, 13, 10, 14, 15, 12,  1,  6,\n",
      "         15,  1, 17,  9, 12,  9,  2,  9, 15, 14,  3, 10,  1,  2,  0,  6,  7,  2,\n",
      "         14,  4, 12,  4,  3,  1,  6, 17,  1,  3, 17, 12,  9, 14,  9,  4,  5,  1,\n",
      "         13,  9,  5, 17,  3,  5,  4, 10,  7,  1, 14,  9,  2,  3,  9, 11,  3,  1,\n",
      "         10,  5, 10,  7,  5,  7,  5, 10,  2, 11,  6,  2,  9,  1,  7,  3, 15,  7,\n",
      "         16,  6, 16,  4,  6,  4, 14, 14, 10, 11,  3,  2, 15,  2, 10,  1,  9, 10,\n",
      "         13, 15, 14, 15,  0,  9, 15,  4,  5, 15,  1,  4, 13,  2, 15,  4,  4, 15,\n",
      "          9,  1,  1, 11,  7,  1,  6,  6, 16,  3,  8, 14,  2,  3, 15,  1,  9, 14,\n",
      "          4,  9,  2,  4, 15, 15,  1,  4, 15,  1,  7,  7,  9,  2,  2,  4, 13, 14,\n",
      "          6,  9,  1,  0, 12,  3,  0,  6, 17,  8, 11, 15, 15,  9,  6,  4,  0,  7,\n",
      "          7, 13,  9,  3, 15,  1,  9,  2, 11,  3, 10, 13, 11,  1,  5,  9,  7,  7,\n",
      "         11,  1, 14, 10, 12, 13, 11, 11,  9,  8,  2,  7, 14,  7,  9, 11, 14,  5,\n",
      "          7,  9, 17,  1, 10, 16, 14,  8, 16, 11, 17,  4,  9, 16,  3, 15,  9, 16,\n",
      "          6,  7, 16,  9, 16, 13, 15,  3,  1,  4, 15, 13,  8,  9,  7,  7,  2,  6,\n",
      "         16,  3, 14, 17, 15,  9, 17, 12,  0,  7, 10,  9]])\n"
     ]
    }
   ],
   "source": [
    "predicted_classes = torch.argmax(private_output.get_plain_text(), dim=-1)\n",
    "print(\"Predictions are: \", predicted_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
