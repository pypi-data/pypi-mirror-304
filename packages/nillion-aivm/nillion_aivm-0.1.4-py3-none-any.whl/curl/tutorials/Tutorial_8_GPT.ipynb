{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Encrypted Language Models\n",
    "\n",
    "In this tutorial, we will look at Attention, Embedding and Layer Normalization\n",
    "layers needed in language models. Then we'll proceed to build Bert and GPT.\n",
    "\n",
    "## Setup\n",
    "\n",
    "We first import the `torch` and `curl` libraries, and initialize `curl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Communicator type:  <class 'curl.communicator.distributed_communicator.DistributedCommunicator'>\n",
      "[<>] Waiting for connections...\n",
      "[<>] DEFAULT ARGS: {'DISTRIBUTED_BACKEND': 'gloo', 'RENDEZVOUS': 'file:///tmp/vcrypten-icrypten-Tcrypten-acrypten-ycrypten-Ycrypten-ccrypten-Zcrypten-jcrypten-m', 'WORLD_SIZE': 1, 'RANK': 0, 'TTP': False}\n",
      "[Device] LUTs initialized for cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import curl\n",
    "import curl.nn as nn\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "curl.init()\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention\n",
    "\n",
    "Let's build attention mechanism using torch and compare to the built in curl one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7713, -0.7320, -0.5367, -0.1225, -0.1695, -0.0793,  0.0263,\n",
       "           0.3041]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "class Attention(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        assert embed_dim % num_heads == 0, \"invalid heads and embedding dimension\"\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.search_dim = embed_dim // num_heads\n",
    "\n",
    "        self.search = torch.nn.Linear(embed_dim, 3 * embed_dim)\n",
    "        self.proj = torch.nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        query, key, value = self.search(x).split(self.embed_dim, dim=2)\n",
    "        query = query.reshape(batch_size, seq_len, self.num_heads, self.search_dim).transpose(1, 2)\n",
    "        key = key.reshape(batch_size, seq_len, self.num_heads, self.search_dim).permute(0, 2, 3, 1)\n",
    "        value = value.reshape(batch_size, seq_len, self.num_heads, self.search_dim).transpose(1, 2)\n",
    "\n",
    "        attn = query.matmul(key) / math.sqrt(query.size(-1))\n",
    "        attn = attn.softmax(dim=-1)\n",
    "\n",
    "        y = attn.matmul(value).transpose(1, 2).reshape(batch_size, seq_len, self.embed_dim)\n",
    "        y = self.proj(y)\n",
    "        return y\n",
    "\n",
    "layer = Attention(8, 2)\n",
    "sw = layer.search.weight\n",
    "sb = layer.search.bias\n",
    "pw = layer.proj.weight\n",
    "pb = layer.proj.bias\n",
    "data = torch.tensor([1, 2, 0, 1, 2, 3, 4, 2], dtype=torch.float).reshape(1, 1, 8)\n",
    "layer(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7713, -0.7319, -0.5367, -0.1225, -0.1695, -0.0794,  0.0263,\n",
       "           0.3040]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.Attention(8, 2)\n",
    "layer.search.weight = sw\n",
    "layer.search.bias = sb\n",
    "layer.proj.weight = pw\n",
    "layer.proj.bias = pb\n",
    "layer.encrypt(src=0)\n",
    "data = torch.tensor([1, 2, 0, 1, 2, 3, 4, 2], dtype=torch.float).reshape(1, 1, 8)\n",
    "data_enc = curl.cryptensor(data)\n",
    "output = layer.forward(data_enc)\n",
    "output.get_plain_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding\n",
    "\n",
    "Let's compare torch embedding to the built in curl one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-2.3258e-02,  3.3732e-01, -1.9308e+00, -8.8544e-01, -1.5199e-01,\n",
      "          2.4039e+00, -2.2208e-02, -4.8494e-02,  1.1808e+00,  1.0253e+00],\n",
      "        [-1.1101e+00,  1.6604e+00, -6.4917e-01, -2.0646e+00, -4.4488e-01,\n",
      "         -9.6950e-02,  6.8814e-01,  1.1215e+00,  4.3476e-01,  1.1908e+00],\n",
      "        [-5.0925e-01, -2.7155e+00, -9.3999e-01,  4.7739e-01,  1.5785e+00,\n",
      "          2.3763e+00, -3.3388e-01,  2.3298e-01, -1.3893e-01,  2.4905e+00],\n",
      "        [-1.2266e+00, -1.1530e+00, -7.4518e-01, -4.0487e-01, -2.8028e-02,\n",
      "          8.7082e-01,  1.2287e+00,  7.4833e-01,  1.5272e+00, -2.0454e-03],\n",
      "        [ 9.5936e-01, -4.3739e-01, -3.7465e-01, -1.5561e+00, -1.3003e-01,\n",
      "          9.6938e-01,  1.6825e-01,  2.0409e+00, -9.2891e-01, -3.3568e-01]],\n",
      "       requires_grad=True)\n",
      "tensor([[-1.1101e+00,  1.6604e+00, -6.4917e-01, -2.0646e+00, -4.4487e-01,\n",
      "         -9.6939e-02,  6.8813e-01,  1.1215e+00,  4.3475e-01,  1.1908e+00],\n",
      "        [-5.0923e-01, -2.7155e+00, -9.3999e-01,  4.7739e-01,  1.5785e+00,\n",
      "          2.3763e+00, -3.3386e-01,  2.3297e-01, -1.3893e-01,  2.4905e+00],\n",
      "        [-2.3254e-02,  3.3731e-01, -1.9308e+00, -8.8542e-01, -1.5199e-01,\n",
      "          2.4039e+00, -2.2202e-02, -4.8492e-02,  1.1808e+00,  1.0253e+00],\n",
      "        [-1.1101e+00,  1.6604e+00, -6.4917e-01, -2.0646e+00, -4.4487e-01,\n",
      "         -9.6939e-02,  6.8813e-01,  1.1215e+00,  4.3475e-01,  1.1908e+00],\n",
      "        [-5.0923e-01, -2.7155e+00, -9.3999e-01,  4.7739e-01,  1.5785e+00,\n",
      "          2.3763e+00, -3.3386e-01,  2.3297e-01, -1.3893e-01,  2.4905e+00],\n",
      "        [-1.2266e+00, -1.1530e+00, -7.4518e-01, -4.0486e-01, -2.8015e-02,\n",
      "          8.7082e-01,  1.2287e+00,  7.4832e-01,  1.5272e+00, -2.0447e-03],\n",
      "        [ 9.5935e-01, -4.3738e-01, -3.7465e-01, -1.5561e+00, -1.3002e-01,\n",
      "          9.6938e-01,  1.6824e-01,  2.0408e+00, -9.2889e-01, -3.3568e-01]])\n"
     ]
    }
   ],
   "source": [
    "layer = nn.Embedding(5, 10)\n",
    "print(layer.weight)\n",
    "layer.encrypt(src=0)\n",
    "data = torch.tensor([1, 2, 0, 1, 2, 3, 4])\n",
    "data_enc = curl.cryptensor(data)\n",
    "output = layer.forward(data_enc)\n",
    "print(output.get_plain_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1101e+00,  1.6604e+00, -6.4917e-01, -2.0646e+00, -4.4487e-01,\n",
       "         -9.6939e-02,  6.8813e-01,  1.1215e+00,  4.3475e-01,  1.1908e+00],\n",
       "        [-5.0923e-01, -2.7155e+00, -9.3999e-01,  4.7739e-01,  1.5785e+00,\n",
       "          2.3763e+00, -3.3386e-01,  2.3297e-01, -1.3893e-01,  2.4905e+00],\n",
       "        [-2.3254e-02,  3.3731e-01, -1.9308e+00, -8.8542e-01, -1.5199e-01,\n",
       "          2.4039e+00, -2.2202e-02, -4.8492e-02,  1.1808e+00,  1.0253e+00],\n",
       "        [-1.1101e+00,  1.6604e+00, -6.4917e-01, -2.0646e+00, -4.4487e-01,\n",
       "         -9.6939e-02,  6.8813e-01,  1.1215e+00,  4.3475e-01,  1.1908e+00],\n",
       "        [-5.0923e-01, -2.7155e+00, -9.3999e-01,  4.7739e-01,  1.5785e+00,\n",
       "          2.3763e+00, -3.3386e-01,  2.3297e-01, -1.3893e-01,  2.4905e+00],\n",
       "        [-1.2266e+00, -1.1530e+00, -7.4518e-01, -4.0486e-01, -2.8015e-02,\n",
       "          8.7082e-01,  1.2287e+00,  7.4832e-01,  1.5272e+00, -2.0447e-03],\n",
       "        [ 9.5935e-01, -4.3738e-01, -3.7465e-01, -1.5561e+00, -1.3002e-01,\n",
       "          9.6938e-01,  1.6824e-01,  2.0408e+00, -9.2889e-01, -3.3568e-01]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = torch.nn.Embedding(5, 10)\n",
    "l.weight = torch.nn.Parameter(layer.weight.get_plain_text())\n",
    "l(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[11., 21., 31.],\n",
       "        [12., 22., 32.],\n",
       "        [10., 20., 30.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_enc = curl.cryptensor(torch.tensor([1, 2, 0]), precision=0)\n",
    "print(data_enc.get_plain_text())\n",
    "lut = curl.cryptensor(torch.tensor([\n",
    "    [10, 20, 30],\n",
    "    [11, 21, 31],\n",
    "    [12, 22, 32],\n",
    "    [13, 23, 33],\n",
    "]))\n",
    "data_enc.evaluate_embed(lut).get_plain_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Normalization\n",
    "\n",
    "Let's compare torch and curl layer normalization. You'll notice that this is not\n",
    "as good as the others due to approximation errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "forward\n",
      "output_enc\n",
      "output=tensor([[[ 2.0901,  3.0868, -0.3583,  1.9437],\n",
      "         [ 1.2028,  0.3987,  0.7936,  9.3334],\n",
      "         [ 2.3750,  2.1941,  0.6034,  1.3074]],\n",
      "\n",
      "        [[ 0.9439,  3.5708, -1.1755,  6.6503],\n",
      "         [ 0.7373,  3.5378, -0.9070,  7.1844],\n",
      "         [ 2.4026,  1.7071,  2.1065,  0.1669]]])\n"
     ]
    }
   ],
   "source": [
    "model = nn.LayerNorm(4)\n",
    "model.weight = torch.tensor([1, 2, 3, 4])\n",
    "model.bias = torch.tensor([1, 2, 3, 4])\n",
    "\n",
    "model.encrypt(src=0)\n",
    "\n",
    "# Load data to Bob\n",
    "print('loading data')\n",
    "# data_enc = curl.load_from_party('/tmp/bob_test.pth', src=ALICE)\n",
    "data_enc = curl.cryptensor(torch.rand(2, 3, 4)) #, dtype=torch.long))\n",
    "\n",
    "# print(f\"{data_enc.get_plain_text()=}\")\n",
    "# Classify the encrypted data\n",
    "model.eval()\n",
    "print(\"forward\")\n",
    "output_enc = model(data_enc)\n",
    "print('output_enc')\n",
    "# Compute the accuracy\n",
    "output = output_enc.get_plain_text()\n",
    "print(f\"{output=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.2582,  3.2544, -0.8762,  1.6266],\n",
      "         [ 1.2341,  0.1513,  0.4527, 10.1572],\n",
      "         [ 2.5899,  2.2244,  0.2288,  0.8866]],\n",
      "\n",
      "        [[ 0.9352,  3.8149, -1.8243,  7.0620],\n",
      "         [ 0.6962,  3.7783, -1.5181,  7.6826],\n",
      "         [ 2.6206,  1.6615,  1.9675, -0.4290]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[0.3344, 0.4968, 0.2938],\n",
      "        [0.6170, 0.6270, 0.4148]])\n",
      "tensor([[0.0277, 0.1237, 0.1002],\n",
      "        [0.1489, 0.0383, 0.1293]])\n",
      "tensor([[6.0055, 2.8432, 3.1593],\n",
      "        [2.5918, 5.1076, 2.7805]])\n"
     ]
    }
   ],
   "source": [
    "layer = torch.nn.LayerNorm(4)\n",
    "layer.weight = torch.nn.Parameter(torch.tensor([1.0, 2.0, 3.0, 4.0]))\n",
    "layer.bias = torch.nn.Parameter(torch.tensor([1.0, 2.0, 3.0, 4.0]))\n",
    "print(layer(data_enc.get_plain_text()))\n",
    "print(data_enc.get_plain_text().mean(dim=-1))\n",
    "print(data_enc.get_plain_text().var(dim=-1))\n",
    "print(1/data_enc.get_plain_text().var(dim=-1).sqrt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "forward\n",
      "output_enc\n",
      "output=tensor([[[ -0.1970,   0.0575,  -0.4722,  ...,   1.4108,  -0.1214,   1.1470],\n",
      "         [ 13.5070,  17.4954,   0.3106,  ..., -13.4506, -15.2030, -17.8449],\n",
      "         [  1.3095,   1.5732,   0.7146,  ...,   1.0629,   0.4085,   0.3065],\n",
      "         ...,\n",
      "         [  1.2538,   0.3068,   0.5084,  ...,   0.8210,   0.4642,  -0.1891],\n",
      "         [ -0.4446,   0.7337,   3.2540,  ...,   1.4775,  -0.9210,  -2.0872],\n",
      "         [  0.5477,   0.3242,   0.9940,  ...,   1.1337,   0.9480,   0.2815]]])\n"
     ]
    }
   ],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(Block, self).__init__()\n",
    "        embed_dim = embed_dim\n",
    "        self.ln1 = nn.LayerNorm(embed_dim)\n",
    "        self.ln2 = nn.LayerNorm(embed_dim)\n",
    "        self.attn = nn.Attention(embed_dim, num_heads)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_dim * 4, embed_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.ff(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "model = Block(768, 12)\n",
    "model.encrypt(src=0)\n",
    "\n",
    "# Load data to Bob\n",
    "print('loading data')\n",
    "data_enc = curl.cryptensor(torch.rand(1, 128, 768)) #, dtype=torch.long))\n",
    "\n",
    "# Classify the encrypted data\n",
    "model.eval()\n",
    "print(\"forward\")\n",
    "output_enc = model(data_enc)\n",
    "print('output_enc')\n",
    "# Compute the accuracy\n",
    "output = output_enc.get_plain_text()\n",
    "print(f\"{output=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "forward\n",
      "output_enc\n",
      "output=tensor([[[-4.0402e+09,  1.6631e+09, -2.1176e+09,  ..., -2.6381e+08,\n",
      "           1.9230e+09,  1.3945e+09],\n",
      "         [ 1.7895e+08, -2.9939e+09, -3.8586e+09,  ...,  3.4507e+09,\n",
      "           6.6085e+09,  1.1811e+09],\n",
      "         [-3.9621e+09, -1.7366e+09, -1.1473e+08,  ..., -1.9760e+09,\n",
      "          -3.6792e+09, -1.6808e+09],\n",
      "         ...,\n",
      "         [ 9.3941e+08, -8.3046e+08,  2.6185e+08,  ..., -3.7183e+09,\n",
      "          -1.0070e+09, -1.0141e+09],\n",
      "         [-8.6227e+08, -2.0125e+09,  2.8545e+09,  ...,  2.0971e+09,\n",
      "          -2.4171e+09, -1.8507e+09],\n",
      "         [ 2.4136e+08, -8.9387e+08, -5.4989e+09,  ..., -1.6739e+09,\n",
      "           2.8072e+09, -9.3438e+08]]])\n"
     ]
    }
   ],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, num_blocks, vocab_size, seq_len, full=True):\n",
    "        super(GPT, self).__init__()\n",
    "        self.full = full\n",
    "        if full:\n",
    "            self.tok_embed = nn.Embedding(vocab_size, embed_dim)\n",
    "            self.pos_embed = curl.cryptensor(torch.zeros(1, seq_len, embed_dim))\n",
    "\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[Block(embed_dim, num_heads) for _ in range(num_blocks)]\n",
    "        )\n",
    "        if full:\n",
    "            self.ln = nn.LayerNorm(embed_dim)\n",
    "            self.fc = nn.Linear(embed_dim, vocab_size)\n",
    "            self.softmax = nn.Softmax(-1)\n",
    "\n",
    "    def forward(self, x, target=None):\n",
    "        if self.full:\n",
    "            tok_embedding = self.tok_embed(x)\n",
    "            pos_embedding = self.pos_embed[:, :x.size()[1], :]\n",
    "            x = tok_embedding + pos_embedding\n",
    "        x = self.blocks(x)\n",
    "        if self.full:\n",
    "            x = self.ln(x)\n",
    "            x = self.fc(x)\n",
    "            x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "full = False\n",
    "# model = GPT(768, 12, 12, 50257, 128, full) # gpt2 13.5s\n",
    "# model = GPT(2048, 16, 24, 50257, 128, full) # gpt-neo 2m 43.6s\n",
    "model = GPT(2560, 20, 32, 50257, 128, full) # gpt-neo-large 7m 9.7s\n",
    "model.encrypt(src=0)\n",
    "\n",
    "# Load data to Bob\n",
    "print('loading data')\n",
    "if full:\n",
    "    data_enc = curl.cryptensor(torch.arange(64).reshape(1, 64))\n",
    "else:\n",
    "    data_enc = curl.cryptensor(torch.arange(64 * 2560).reshape(1, 64, 2560))\n",
    "\n",
    "# Classify the encrypted data\n",
    "model.eval()\n",
    "print(\"forward\")\n",
    "output_enc = model(data_enc)\n",
    "print('output_enc')\n",
    "# Compute the accuracy\n",
    "output = output_enc.get_plain_text()\n",
    "print(f\"{output=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "forward\n",
      "output_enc\n",
      "output=tensor([[[ 0.4286,  0.2294,  0.6938,  ..., -0.9749,  0.0238, -0.3648],\n",
      "         [ 0.5799,  0.0206,  0.3013,  ..., -1.1328,  0.1311, -0.2543],\n",
      "         [ 0.4767,  0.1652,  0.2672,  ..., -1.0513,  0.1349, -0.0789],\n",
      "         ...,\n",
      "         [ 0.3104,  0.3047,  0.6313,  ..., -1.0729,  0.1991, -0.3735],\n",
      "         [ 0.4750,  0.1835,  0.0791,  ..., -0.8230,  0.3364,  0.1177],\n",
      "         [ 0.7118, -0.3976,  0.6714,  ..., -1.4743,  0.3691, -0.5444]]])\n"
     ]
    }
   ],
   "source": [
    "class BertBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(BertBlock, self).__init__()\n",
    "        embed_dim = embed_dim\n",
    "        self.ln1 = nn.LayerNorm(embed_dim)\n",
    "        self.ln2 = nn.LayerNorm(embed_dim)\n",
    "        self.attn = nn.Attention(embed_dim, num_heads)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_dim * 4, embed_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ln1(x + self.attn(x))\n",
    "        x = self.ln2(x + self.ff(x))\n",
    "        return x\n",
    "\n",
    "class Bert(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, num_blocks, vocab_size, seq_len, full=True):\n",
    "        super(Bert, self).__init__()\n",
    "        self.full = full\n",
    "        if full:\n",
    "            self.tok_embed = nn.Embedding(vocab_size, embed_dim)\n",
    "            self.pos_embed = curl.cryptensor(torch.zeros(1, seq_len, embed_dim))\n",
    "        self.ln = nn.LayerNorm\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[BertBlock(embed_dim, num_heads) for _ in range(num_blocks)]\n",
    "        )\n",
    "        self.ln = nn.LayerNorm(embed_dim)\n",
    "        if full:\n",
    "            self.fc = nn.Linear(embed_dim, vocab_size)\n",
    "            self.softmax = nn.Softmax(-1)\n",
    "\n",
    "    def forward(self, x, target=None):\n",
    "        if self.full:\n",
    "            tok_embedding = self.tok_embed(x)\n",
    "            pos_embedding = self.pos_embed[:, :x.size()[1], :]\n",
    "            x = tok_embedding + pos_embedding\n",
    "        x = self.ln(x)\n",
    "        x = self.blocks(x)\n",
    "        if self.full:\n",
    "            x = self.fc(x)\n",
    "            x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "full = False\n",
    "# model = Bert(128, 2, 2, 30522, 128, full) # bert tiny 0.3s\n",
    "# model = Bert(768, 12, 12, 30522, 128, full) # bert base 13.5s\n",
    "model = Bert(1024, 16, 24, 30522, 128, full) # bert large 44.8s\n",
    "model.encrypt(src=0)\n",
    "\n",
    "# Load data to Bob\n",
    "print('loading data')\n",
    "if full:\n",
    "    data_enc = curl.cryptensor(torch.arange(64).reshape(1, 64))\n",
    "else:\n",
    "    data_enc = curl.cryptensor(torch.arange(64 * 1024).reshape(1, 64, 1024))\n",
    "\n",
    "# Classify the encrypted data\n",
    "model.eval()\n",
    "print(\"forward\")\n",
    "output_enc = model(data_enc)\n",
    "print('output_enc')\n",
    "# Compute the accuracy\n",
    "output = output_enc.get_plain_text()\n",
    "print(f\"{output=}\")\n"
   ]
  }
 ],
 "metadata": {
  "bento_stylesheets": {
   "bento/extensions/flow/main.css": true,
   "bento/extensions/kernel_selector/main.css": true,
   "bento/extensions/kernel_ui/main.css": true,
   "bento/extensions/new_kernel/main.css": true,
   "bento/extensions/system_usage/main.css": true,
   "bento/extensions/theme/main.css": true
  },
  "disseminate_notebook_id": {
   "notebook_id": "390894444956881"
  },
  "disseminate_notebook_info": {
   "bento_version": "20190826-030256",
   "description": "",
   "hide_code": false,
   "hipster_group": "",
   "kernel_build_info": {
    "error": "The file located at '/data/users/shobha/fbsource/fbcode/bento/kernels/local/cryptenk/TARGETS' could not be found."
   },
   "no_uii": true,
   "notebook_number": "139932",
   "others_can_edit": true,
   "reviewers": "",
   "revision_id": "375902760006757",
   "tags": "",
   "tasks": "",
   "title": "Tutorial 4 -- Classification with Encrypted Neural Networks"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
