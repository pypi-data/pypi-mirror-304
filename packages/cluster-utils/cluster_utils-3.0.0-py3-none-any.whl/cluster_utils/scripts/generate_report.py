#!/usr/bin/env python3
"""Generate PDF report of a cluster run.

As input it expects the path to a results directory containing the files generated
during the cluster run.
"""
from __future__ import annotations

import argparse
import contextlib
import datetime
import json
import logging
import pathlib
import pickle
import sys
import typing

import colorama
import pandas as pd

from cluster_utils.base.constants import (
    FULL_DF_FILE,
    METADATA_FILE,
    REPORT_DATA_FILE,
    STATUS_PICKLE_FILE,
)
from cluster_utils.server import report
from cluster_utils.server.optimizers import Optimizer
from cluster_utils.server.utils import ClusterRunType

LOGGER_NAME = "generate_report"


class Metadata(typing.NamedTuple):
    """Metadata of the cluster run."""

    #: Which type of run was used.
    run_type: ClusterRunType
    #: Timestamp of the start of the run.
    start_time: datetime.datetime

    @staticmethod
    def load(results_dir: pathlib.Path) -> Metadata:
        """Load metadata from file.

        Args:
            results_dir: Directory containing the files generated by the cluster run.
        """
        metadata_file = results_dir / METADATA_FILE
        with open(metadata_file) as f:
            metadata = json.load(f)

        return Metadata(
            run_type=ClusterRunType[metadata["run_type"]],
            start_time=datetime.datetime.fromisoformat(metadata["start_time"]),
        )


def initialize_logger(name: str, verbose: bool) -> logging.Logger:
    """Initialise and return logger instance."""

    class ColouredFormatter(logging.Formatter):
        STYLES = {
            "WARNING": colorama.Fore.YELLOW,
            "INFO": colorama.Fore.BLUE,
            "DEBUG": colorama.Fore.GREEN,
            "CRITICAL": colorama.Fore.RED + colorama.Style.BRIGHT,
            "ERROR": colorama.Fore.RED,
        }

        def __init__(self, *, fmt):
            logging.Formatter.__init__(self, fmt=fmt)

        def format(self, record: logging.LogRecord) -> str:
            msg = super().format(record)
            try:
                return f"{self.STYLES[record.levelname]}{msg}{colorama.Style.RESET_ALL}"
            except KeyError:
                return msg

    log_handler = logging.StreamHandler()
    log_handler.setFormatter(
        ColouredFormatter(fmt="[%(asctime)s] [%(name)s | %(levelname)s] %(message)s")
    )

    logger = logging.getLogger(name)
    logger.addHandler(log_handler)
    logger.setLevel(logging.DEBUG if verbose else logging.INFO)

    return logger


def generate_hp_optimization_report(
    results_dir: pathlib.Path, output_file: pathlib.Path, metadata: Metadata
) -> None:
    logger = logging.getLogger(LOGGER_NAME)

    status_file = results_dir / STATUS_PICKLE_FILE
    logger.debug("Read file %s", status_file)
    with open(status_file, "rb") as f:
        optimizer: Optimizer = pickle.load(f)

    report_data_file = results_dir / REPORT_DATA_FILE
    logger.debug("Read file %s", report_data_file)
    with open(report_data_file, "rb") as f:
        report_data = pickle.load(f)

    if not isinstance(optimizer, Optimizer):
        logger.warning("Object loaded from '%s' is not of type Optimizer", status_file)

    report.produce_optimization_report(
        optimizer,
        output_file,
        report_data["submission_hook_stats"],
        results_dir,
        metadata.start_time,
    )


def generate_grid_search_report(
    results_dir: pathlib.Path, output_file: pathlib.Path, metadata: Metadata
) -> None:
    logger = logging.getLogger(LOGGER_NAME)

    data_file = results_dir / FULL_DF_FILE
    other_info_file = results_dir / REPORT_DATA_FILE

    logger.debug("Read file %s", data_file)
    data = pd.read_csv(data_file)

    logger.debug("Read file %s", other_info_file)
    with open(other_info_file, "rb") as f:
        other_info = pickle.load(f)

    report.produce_gridsearch_report(
        data,
        output_file=output_file,
        start_time=metadata.start_time,
        **other_info,
    )


def main() -> int:
    parser = argparse.ArgumentParser(
        description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument(
        "results_dir",
        type=pathlib.Path,
        help="Directory containing the generated files.",
        metavar="RESULTS_DIRECTORY",
    )
    parser.add_argument(
        "output",
        type=pathlib.Path,
        help="Where to save the report.",
        metavar="OUTPUT_FILE",
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="Overwrite existing output file without asking.",
    )
    parser.add_argument(
        "--verbose", "-v", action="store_true", help="Enable verbose output."
    )
    args = parser.parse_args()

    logger = initialize_logger(LOGGER_NAME, args.verbose)

    if not args.results_dir.is_dir():
        logger.fatal("'%s' does not exist or is not a directory", args.results_dir)
        return 1

    try:
        metadata = Metadata.load(args.results_dir)
    except FileNotFoundError:
        logger.fatal(
            "No metadata file found.  Either '%s' is not a results directory of a"
            " cluster_utils run or it is from an older version that did not yet"
            " save '%s'.",
            args.results_dir,
            METADATA_FILE,
        )
        return 1
    except Exception as e:
        logger.fatal("Failed to read '%s': %s", METADATA_FILE, e)
        return 1

    # do not overwrite existing files without confirmation
    if args.output.exists():
        if args.force:
            logger.warning(
                f"{args.output} already exists but will be overwritten due to --force."
            )
        else:
            val = input(f"{args.output} already exists.  Overwrite it? [y/N]: ")
            if val.lower() not in ["y", "yes"]:
                print("Do not overwrite existing file.  Abort.")
                return 1

    if metadata.run_type == ClusterRunType.HP_OPTIMIZATION:
        logger.info("Generate hp_optimization report")
        generate_hp_optimization_report(args.results_dir, args.output, metadata)
    elif metadata.run_type == ClusterRunType.GRID_SEARCH:
        logger.info("Generate grid_search report")
        generate_grid_search_report(args.results_dir, args.output, metadata)
    else:
        # this should never happen but catch it just in case...
        raise NotImplementedError("Unsupported cluster run type")

    logger.info("Saved report to %s", args.output)

    return 0


if __name__ == "__main__":
    with contextlib.suppress(KeyboardInterrupt):
        sys.exit(main())
