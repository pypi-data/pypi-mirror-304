Metadata-Version: 2.1
Name: bpm-ai-inference
Version: 0.3.6
Summary: Inference and server for local AI implementations of bpm-ai-core abstractions.
Home-page: https://www.holisticon.de/
License: GPL-3.0-or-later
Author: Bennet Krause
Author-email: bennet.krause@holisticon.de
Requires-Python: >=3.11,<3.12
Classifier: License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.11
Requires-Dist: bpm-ai-core (>=2.6.2,<3.0.0)
Requires-Dist: faster-whisper (>=0.10.0,<0.11.0)
Requires-Dist: gliner (>=0.1.6,<0.2.0)
Requires-Dist: langfuse (>=2.7.6,<3.0.0)
Requires-Dist: lingua-language-detector (>=2.0.2,<3.0.0)
Requires-Dist: llama-cpp-python (>=0.3.1,<0.4.0)
Requires-Dist: nltk (>=3.8.0,<4.0.0)
Requires-Dist: optimum[onnxruntime] (>=1.18.0,<2.0.0)
Requires-Dist: py-cpuinfo (>=9.0.0,<10.0.0)
Requires-Dist: pytesseract (>=0.3.10,<0.4.0)
Requires-Dist: sacremoses (>=0.1.1,<0.2.0)
Requires-Dist: scipy (==1.10.1)
Requires-Dist: sentencepiece (>=0.2.0,<0.3.0)
Requires-Dist: transformers (>=4.39.3,<5.0.0)
Project-URL: Repository, https://github.com/holunda-io/bpm-ai-inference
Description-Content-Type: text/markdown

# bpm-ai-inference

Extension to bpm-ai project for local AI inference.

## Install platform specific dependencies
### Linux
Install PyTorch (with CUDA GPU support) and spaCy:
```bash
$ pip install -r requirements.txt
```
or CPU-only:
```bash
$ pip install -r requirements.linux-cpu.txt
```

### Apple Silicon:
```bash
$ pip install -r requirements.apple.txt
```

## Install from PyPi
```bash
$ pip install bpm-ai-inference
```

## License

This project is developed under

[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)

due to dependency licenses.

## Sponsors and Customers

[![sponsored](https://img.shields.io/badge/sponsoredBy-Holisticon-red.svg)](https://holisticon.de/)

