Metadata-Version: 2.1
Name: roicat
Version: 1.4.3
Summary: A library for classifying and tracking ROIs.
Home-page: https://github.com/RichieHakim/ROICaT
Author: Richard Hakim
License: LICENSE
Keywords: neuroscience,neuroimaging,machine learning,deep learning
Requires-Python: >=3.10, <3.13
Description-Content-Type: text/markdown
License-File: LICENSE.md
Provides-Extra: all
Requires-Dist: hdbscan ==0.8.39 ; extra == 'all'
Requires-Dist: holoviews[recommended] ==1.19.1 ; extra == 'all'
Requires-Dist: jupyter ==1.0.0 ; extra == 'all'
Requires-Dist: kymatio ==0.3.0 ; extra == 'all'
Requires-Dist: matplotlib ==3.9.2 ; extra == 'all'
Requires-Dist: natsort ==8.4.0 ; extra == 'all'
Requires-Dist: numpy ==2.0.2 ; extra == 'all'
Requires-Dist: opencv-contrib-python-headless <=4.10.0.84 ; extra == 'all'
Requires-Dist: optuna ==4.0.0 ; extra == 'all'
Requires-Dist: Pillow ==11.0.0 ; extra == 'all'
Requires-Dist: pytest ==8.3.3 ; extra == 'all'
Requires-Dist: scikit-learn ==1.5.2 ; extra == 'all'
Requires-Dist: scipy ==1.14.1 ; extra == 'all'
Requires-Dist: seaborn ==0.13.2 ; extra == 'all'
Requires-Dist: sparse ==0.15.4 ; extra == 'all'
Requires-Dist: tqdm ==4.66.5 ; extra == 'all'
Requires-Dist: umap-learn ==0.5.6 ; extra == 'all'
Requires-Dist: xxhash ==3.5.0 ; extra == 'all'
Requires-Dist: bokeh ==3.6.0 ; extra == 'all'
Requires-Dist: psutil ==6.1.0 ; extra == 'all'
Requires-Dist: py-cpuinfo ==9.0.0 ; extra == 'all'
Requires-Dist: GPUtil ==1.4.0 ; extra == 'all'
Requires-Dist: PyYAML ==6.0.2 ; extra == 'all'
Requires-Dist: mat73 ==0.65 ; extra == 'all'
Requires-Dist: torch ==2.5.0 ; extra == 'all'
Requires-Dist: torchvision ==0.20.0 ; extra == 'all'
Requires-Dist: torchaudio ==2.5.0 ; extra == 'all'
Requires-Dist: selenium ==4.25.0 ; extra == 'all'
Requires-Dist: skl2onnx ==1.17.0 ; extra == 'all'
Requires-Dist: onnx ==1.17.0 ; extra == 'all'
Requires-Dist: onnxruntime ==1.19.2 ; extra == 'all'
Requires-Dist: jupyter-bokeh ==4.0.5 ; extra == 'all'
Requires-Dist: onnx2torch ==1.5.15 ; extra == 'all'
Requires-Dist: scikit-image ==0.24.0 ; extra == 'all'
Requires-Dist: richfile >=0.4.5 ; extra == 'all'
Requires-Dist: romatch-roicat >=0.1.0 ; extra == 'all'
Requires-Dist: kornia ==0.7.3 ; extra == 'all'
Provides-Extra: all_latest
Requires-Dist: hdbscan ; extra == 'all_latest'
Requires-Dist: holoviews[recommended] ; extra == 'all_latest'
Requires-Dist: jupyter ; extra == 'all_latest'
Requires-Dist: kymatio ; extra == 'all_latest'
Requires-Dist: matplotlib ; extra == 'all_latest'
Requires-Dist: natsort ; extra == 'all_latest'
Requires-Dist: numpy ; extra == 'all_latest'
Requires-Dist: opencv-contrib-python-headless ; extra == 'all_latest'
Requires-Dist: optuna ; extra == 'all_latest'
Requires-Dist: Pillow ; extra == 'all_latest'
Requires-Dist: pytest ; extra == 'all_latest'
Requires-Dist: scikit-learn ; extra == 'all_latest'
Requires-Dist: scipy ; extra == 'all_latest'
Requires-Dist: seaborn ; extra == 'all_latest'
Requires-Dist: sparse ; extra == 'all_latest'
Requires-Dist: tqdm ; extra == 'all_latest'
Requires-Dist: umap-learn ; extra == 'all_latest'
Requires-Dist: xxhash ; extra == 'all_latest'
Requires-Dist: bokeh ; extra == 'all_latest'
Requires-Dist: psutil ; extra == 'all_latest'
Requires-Dist: py-cpuinfo ; extra == 'all_latest'
Requires-Dist: GPUtil ; extra == 'all_latest'
Requires-Dist: PyYAML ; extra == 'all_latest'
Requires-Dist: mat73 ; extra == 'all_latest'
Requires-Dist: torch ; extra == 'all_latest'
Requires-Dist: torchvision ; extra == 'all_latest'
Requires-Dist: torchaudio ; extra == 'all_latest'
Requires-Dist: selenium ; extra == 'all_latest'
Requires-Dist: skl2onnx ; extra == 'all_latest'
Requires-Dist: onnx ; extra == 'all_latest'
Requires-Dist: onnxruntime ; extra == 'all_latest'
Requires-Dist: jupyter-bokeh ; extra == 'all_latest'
Requires-Dist: onnx2torch ; extra == 'all_latest'
Requires-Dist: scikit-image ; extra == 'all_latest'
Requires-Dist: richfile ; extra == 'all_latest'
Requires-Dist: romatch-roicat ; extra == 'all_latest'
Requires-Dist: kornia ; extra == 'all_latest'
Provides-Extra: classification
Requires-Dist: umap-learn ==0.5.6 ; extra == 'classification'
Requires-Dist: bokeh ==3.6.0 ; extra == 'classification'
Requires-Dist: holoviews[recommended] ==1.19.1 ; extra == 'classification'
Requires-Dist: jupyter-bokeh ==4.0.5 ; extra == 'classification'
Requires-Dist: jupyter ==1.0.0 ; extra == 'classification'
Requires-Dist: matplotlib ==3.9.2 ; extra == 'classification'
Requires-Dist: mat73 ==0.65 ; extra == 'classification'
Requires-Dist: natsort ==8.4.0 ; extra == 'classification'
Requires-Dist: numpy ==2.0.2 ; extra == 'classification'
Requires-Dist: optuna ==4.0.0 ; extra == 'classification'
Requires-Dist: Pillow ==11.0.0 ; extra == 'classification'
Requires-Dist: pytest ==8.3.3 ; extra == 'classification'
Requires-Dist: PyYAML ==6.0.2 ; extra == 'classification'
Requires-Dist: scikit-learn ==1.5.2 ; extra == 'classification'
Requires-Dist: scipy ==1.14.1 ; extra == 'classification'
Requires-Dist: seaborn ==0.13.2 ; extra == 'classification'
Requires-Dist: sparse ==0.15.4 ; extra == 'classification'
Requires-Dist: tqdm ==4.66.5 ; extra == 'classification'
Requires-Dist: xxhash ==3.5.0 ; extra == 'classification'
Requires-Dist: torch ==2.5.0 ; extra == 'classification'
Requires-Dist: torchvision ==0.20.0 ; extra == 'classification'
Requires-Dist: torchaudio ==2.5.0 ; extra == 'classification'
Requires-Dist: psutil ==6.1.0 ; extra == 'classification'
Requires-Dist: py-cpuinfo ==9.0.0 ; extra == 'classification'
Requires-Dist: GPUtil ==1.4.0 ; extra == 'classification'
Requires-Dist: skl2onnx ==1.17.0 ; extra == 'classification'
Requires-Dist: onnx ==1.17.0 ; extra == 'classification'
Requires-Dist: onnxruntime ==1.19.2 ; extra == 'classification'
Requires-Dist: richfile >=0.4.5 ; extra == 'classification'
Provides-Extra: core
Requires-Dist: jupyter ==1.0.0 ; extra == 'core'
Requires-Dist: matplotlib ==3.9.2 ; extra == 'core'
Requires-Dist: mat73 ==0.65 ; extra == 'core'
Requires-Dist: natsort ==8.4.0 ; extra == 'core'
Requires-Dist: numpy ==2.0.2 ; extra == 'core'
Requires-Dist: optuna ==4.0.0 ; extra == 'core'
Requires-Dist: Pillow ==11.0.0 ; extra == 'core'
Requires-Dist: pytest ==8.3.3 ; extra == 'core'
Requires-Dist: PyYAML ==6.0.2 ; extra == 'core'
Requires-Dist: scikit-learn ==1.5.2 ; extra == 'core'
Requires-Dist: scipy ==1.14.1 ; extra == 'core'
Requires-Dist: seaborn ==0.13.2 ; extra == 'core'
Requires-Dist: sparse ==0.15.4 ; extra == 'core'
Requires-Dist: tqdm ==4.66.5 ; extra == 'core'
Requires-Dist: xxhash ==3.5.0 ; extra == 'core'
Requires-Dist: torch ==2.5.0 ; extra == 'core'
Requires-Dist: torchvision ==0.20.0 ; extra == 'core'
Requires-Dist: torchaudio ==2.5.0 ; extra == 'core'
Requires-Dist: psutil ==6.1.0 ; extra == 'core'
Requires-Dist: py-cpuinfo ==9.0.0 ; extra == 'core'
Requires-Dist: GPUtil ==1.4.0 ; extra == 'core'
Requires-Dist: skl2onnx ==1.17.0 ; extra == 'core'
Requires-Dist: onnx ==1.17.0 ; extra == 'core'
Requires-Dist: onnxruntime ==1.19.2 ; extra == 'core'
Requires-Dist: richfile >=0.4.5 ; extra == 'core'
Provides-Extra: tracking
Requires-Dist: opencv-contrib-python-headless <=4.10.0.84 ; extra == 'tracking'
Requires-Dist: hdbscan ==0.8.39 ; extra == 'tracking'
Requires-Dist: kymatio ==0.3.0 ; extra == 'tracking'
Requires-Dist: kornia ==0.7.3 ; extra == 'tracking'
Requires-Dist: romatch-roicat >=0.1.0 ; extra == 'tracking'
Requires-Dist: jupyter ==1.0.0 ; extra == 'tracking'
Requires-Dist: matplotlib ==3.9.2 ; extra == 'tracking'
Requires-Dist: mat73 ==0.65 ; extra == 'tracking'
Requires-Dist: natsort ==8.4.0 ; extra == 'tracking'
Requires-Dist: numpy ==2.0.2 ; extra == 'tracking'
Requires-Dist: optuna ==4.0.0 ; extra == 'tracking'
Requires-Dist: Pillow ==11.0.0 ; extra == 'tracking'
Requires-Dist: pytest ==8.3.3 ; extra == 'tracking'
Requires-Dist: PyYAML ==6.0.2 ; extra == 'tracking'
Requires-Dist: scikit-learn ==1.5.2 ; extra == 'tracking'
Requires-Dist: scipy ==1.14.1 ; extra == 'tracking'
Requires-Dist: seaborn ==0.13.2 ; extra == 'tracking'
Requires-Dist: sparse ==0.15.4 ; extra == 'tracking'
Requires-Dist: tqdm ==4.66.5 ; extra == 'tracking'
Requires-Dist: xxhash ==3.5.0 ; extra == 'tracking'
Requires-Dist: torch ==2.5.0 ; extra == 'tracking'
Requires-Dist: torchvision ==0.20.0 ; extra == 'tracking'
Requires-Dist: torchaudio ==2.5.0 ; extra == 'tracking'
Requires-Dist: psutil ==6.1.0 ; extra == 'tracking'
Requires-Dist: py-cpuinfo ==9.0.0 ; extra == 'tracking'
Requires-Dist: GPUtil ==1.4.0 ; extra == 'tracking'
Requires-Dist: skl2onnx ==1.17.0 ; extra == 'tracking'
Requires-Dist: onnx ==1.17.0 ; extra == 'tracking'
Requires-Dist: onnxruntime ==1.19.2 ; extra == 'tracking'
Requires-Dist: richfile >=0.4.5 ; extra == 'tracking'

# Welcome to ROICaT

<div>
    <img src="docs/media/logo1.png" alt="ROICaT" width="200"  align="right"  style="margin-left: 20px"/>
</div>

[![build](https://github.com/RichieHakim/ROICaT/actions/workflows/.github/workflows/build.yml/badge.svg)](https://github.com/RichieHakim/ROICaT/actions/workflows/build.yml) 
[![PyPI version](https://badge.fury.io/py/roicat.svg)](https://badge.fury.io/py/roicat)
[![Downloads](https://pepy.tech/badge/roicat)](https://pepy.tech/project/roicat)

- **Documentation: [https://roicat.readthedocs.io/en/latest/](https://roicat.readthedocs.io/en/latest/)**
- Discussion forum: [https://groups.google.com/g/roicat_support](https://groups.google.com/g/roicat_support)
- Technical support: [Github Issues](https://github.com/RichieHakim/ROICaT/issues)

## **R**egion **O**f **I**nterest **C**lassification **a**nd **T**racking á—¢
A simple-to-use Python package for automatically classifying images of cells and tracking them across imaging sessions/planes.
<div>
    <img src="docs/media/tracking_FOV_clusters_rich.gif" alt="tracking_FOV_clusters_rich"  width="400"  align="right" style="margin-left: 20px"/>
</div>

**Why use ROICaT?**
- **It's easy to use. You don't need to know how to code. You can use the
  interactive notebooks or online app to run the pipelines with just a few
  clicks.**
- It's accurate. ROICaT was desgined to be better than existing tools. It is
  capable of classifying and tracking neuron ROIs at accuracies approaching
  human performance out of the box.
- It's fast and computational requirements are low. You can run it on a laptop.
  It was designed to be used with >1M ROIs, and can utilize GPUs to speed things
  up.

With ROICaT, you can:
- **Classify ROIs** into different categories (e.g. neurons, dendrites, glia,
  etc.).
- **Track ROIs** across imaging sessions/planes (e.g. ROI #1 in session 1 is the
  same as ROI #7 in session 2).

**What data types can ROICaT process?** 
- ROICaT can accept any imaging data format including: Suite2p, CaImAn, CNMF,
  NWB, raw/custom ROI data and more. See below for details on how to use any
  data type with ROICaT.

<br>
<br>

# How to use ROICaT
<div>
    <img src="docs/media/umap_with_labels.png" alt="ROICaT" width="300"  align="right"  style="margin-left: 20px"/>
</div>

Listed below, we have a suite of tools for running the ROICaT pipelines. 
#### First time users:
Try it out using the online app or our Google CoLab notebooks below which can be
run fully remotely without installing anything on your computer.
#### Normal usage:
We recommend using our Jupyter notebooks or command line interface which can be
run locally on any computer.

### TRACKING: 
- [Online App](https://huggingface.co/spaces/richiehakim/ROICaT_tracking): Good for first time users. Try it out without installing anything.
- [Interactive
  notebook](https://github.com/RichieHakim/ROICaT/blob/main/notebooks/jupyter/tracking/1_tracking_interactive_notebook.ipynb)
- [Google
  CoLab](https://githubtocolab.com/RichieHakim/ROICaT/blob/main/notebooks/colab/tracking/1_tracking_interactive_notebook.ipynb) (not up to date)
- [Command line interface script](https://github.com/RichieHakim/ROICaT/blob/main/scripts/run_tracking.sh): 
```shell
roicat --pipeline tracking --path_params /path/to/params.yaml --dir_data /folder/with/data/ --dir_save /folder/save/ --prefix_name_save expName --verbose
```
  
### CLASSIFICATION:
- [Interactive notebook -
  Drawing](https://github.com/RichieHakim/ROICaT/blob/main/notebooks/jupyter/classification/A1_classify_by_drawingSelection.ipynb)
- [Google CoLab -
  Drawing](https://githubtocolab.com/RichieHakim/ROICaT/blob/main/notebooks/colab/classification/A1_classify_by_drawingSelection_colab.ipynb) (not up to date)
- [Interactive notebook -
  Labeling](https://github.com/RichieHakim/ROICaT/blob/main/notebooks/jupyter/classification/B1_labeling_interactive.ipynb)
- [Interactive notebook - Train
  classifier](https://github.com/RichieHakim/ROICaT/blob/main/notebooks/jupyter/classification/B2_classifier_train_interactive.ipynb)
- [Interactive notebook - Inference with
  classifier](https://github.com/RichieHakim/ROICaT/blob/main/notebooks/jupyter/classification/B3_classifier_inference_interactive.ipynb)

**OTHER:** 
- [Custom data importing
  notebook](https://github.com/RichieHakim/ROICaT/blob/main/notebooks/jupyter/other/demo_data_importing.ipynb)
- Use the API to integrate ROICaT functions into your own code:
  [Documentation](https://roicat.readthedocs.io/en/latest/roicat.html).
- Run the full tracking pipeline using `roicat.pipelines.pipeline_tracking` with
  default parameters generated from `roicat.util.get_default_paramaters()`.
<!-- - Train a new ROInet model using the provided Jupyter Notebook [TODO: link]. -->

# General workflow:
- **Pass ROIs through ROInet:** Images of the ROIs are passed through a neural
  network which outputs a feature vector for each image describing what the ROI
  looks like.
-  **Classification:** The feature vectors can then be used to classify ROIs:
   - A simple regression-like classifier can be trained using user-supplied
     labeled data (e.g. an array of images of ROIs and a corresponding array of
     labels for each ROI).
   - Alternatively, classification can be done by projecting the feature vectors
     into a lower-dimensional space using UMAP and then simply circling the
     region of space to classify the ROIs.
-  **Tracking**: The feature vectors can be combined with information about the
   position of the ROIs to track the ROIs across imaging sessions/planes.


# Installation
ROICaT works on Windows, MacOS, and Linux. If you have any issues during the
installation process, please make a [github
issue](https://github.com/RichieHakim/ROICaT/issues) with the error.

### 0. Requirements
- [Anaconda](https://www.anaconda.com/distribution/) or
  [Miniconda](https://docs.conda.io/en/latest/miniconda.html).
- If using Windows: [Microsoft C++ Build
  Tools](https://visualstudio.microsoft.com/visual-cpp-build-tools/)
- The below commands should be run in the terminal (Mac/Linux) or Anaconda
  Prompt (Windows).

### 1. (Recommended) Create a new conda environment
```
conda create -n roicat python=3.12
conda activate roicat
```
You will need to activate the environment with `conda activate roicat` each time
you want to use ROICaT.

### 2. Install ROICaT
```
pip install roicat[all]
pip install git+https://github.com/RichieHakim/roiextractors
```
**Note on zsh:** if you are using a zsh terminal, change command to: `pip3
install --user 'roicat[all]'` For installing GPU support on Windows, see
[Troubleshooting](#troubleshooting-gpu-support) below. 
<br>
**Note on opencv:** The headless version of opencv is installed by default. If
the regular version is already installed, you will need to uninstall it first.

### 3. Clone the repo to get the notebooks
```
git clone https://github.com/RichieHakim/ROICaT
```
Then, navigate to the `ROICaT/notebooks/jupyter` directory to run the notebooks.


# Upgrading versions
There are 2 parts to upgrading ROICaT: the **Python package** and the
**repository files** which contain the notebooks and scripts.\
Activate your environment first, then...\
To upgrade the Python package, run:
```
pip install --upgrade roicat[all]
```
To upgrade the repository files, navigate your terminal to the `ROICaT` folder and run:
```
git pull
```


# TODO:
#### algorithmic improvements:
- [ ] Add in method to use more similarity metrics for tracking
- [ ] Coordinate descent on each similarity metric
- [ ] Add F and Fneu to data_roicat, dFoF and trace quality metric functions
- [ ] Add in notebook for demonstrating using temporal similarity metrics (SWT on dFoF)
- [ ] Make a standard classifier
- [ ] Try other clustering methods
- [x] Make image aligner based on image similarity + RANSAC of centroids or s_SF
- [ ] Better post-hoc curation metrics and visualizations
#### code improvements:
- [ ] Update automatic regression module (make new repo for it)
- [ ] Switch to ONNX for ROInet
- [ ] Some more integration tests
- [ ] Add more documentation / tutorials
- [x] Make a GUI
- [ ] Finish ROIextractors integration
- [ ] Make a Docker container
- [ ] Make colab demo notebook not require user data
- [x] Make a better CLI
#### other:
- [ ] Write the paper
- [ ] Make tweet about it
- [ ] Make a video or two on how to use it
- [ ] Maybe use lightthetorch for torch installation
- [ ] Better Readme
- [ ] More documentation
- [ ] Make a regression model for in-plane-ness
