Metadata-Version: 2.1
Name: pxia
Version: 0.2.0
Summary: a repository for pxia models
Home-page: https://github.com/not-lain/pxia
License: Apache 2.0 License
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 3.10
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: setuptools>=42
Requires-Dist: wheel>=0.37
Requires-Dist: torch>=2.2.1
Requires-Dist: huggingface-hub>=0.24
Requires-Dist: omegaconf

# PXIA
A repository for pxia models 

This repository is using HuggingFace's PyTorchModelHubMixin classes

[![Downloads](https://static.pepy.tech/badge/pxia)](https://pepy.tech/project/pxia)

## How to use

```
pip install pxia
```

```python
from pxia import GPT2
model = GPT2(block_size= 1024, vocab_size = 50257, n_layer= 11, n_head= 12, n_embed = 768) # or use default parameters
model.push_to_hub("phxia/gpt2")

pretrained_model = GPT2.from_pretrained("phxia/gpt2")
```

alternatively you can load weights from source gpt2 models from huggingface and convert them to pxia format

```python
model = GPT2.from_origin("openai-community/gpt2")
```

we also support `AutoModel` class in our repository
to load any pxia model either locally or from the hub you can 
```python
from pxia import AutoModel
model = AutoModel.from_pretrained("phxia/gpt2")
```

![pxia](https://github.com/not-lain/pxia/blob/main/logo.png?raw=true)
