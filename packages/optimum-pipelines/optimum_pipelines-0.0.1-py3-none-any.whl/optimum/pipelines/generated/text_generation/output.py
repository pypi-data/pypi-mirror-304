# generated by datamodel-codegen:
#   filename:  output.json
#   timestamp: 2024-10-25T08:14:28+00:00

from __future__ import annotations

from enum import Enum
from typing import List, Optional

from pydantic import BaseModel, Field, conint


class TextGenerationOutputFinishReason(Enum):
    length = "length"
    eos_token = "eos_token"
    stop_sequence = "stop_sequence"


class TextGenerationOutputPrefillToken(BaseModel):
    id: conint(ge=0) = Field(..., examples=[0])
    logprob: float = Field(..., examples=[-0.34])
    text: str = Field(..., examples=["test"])


class TextGenerationOutputToken(BaseModel):
    id: conint(ge=0) = Field(..., examples=[0])
    logprob: float = Field(..., examples=[-0.34])
    special: bool = Field(..., examples=["false"])
    text: str = Field(..., examples=["test"])


class TextGenerationOutputBestOfSequence(BaseModel):
    finish_reason: TextGenerationOutputFinishReason
    generated_text: str = Field(..., examples=["test"])
    generated_tokens: conint(ge=0) = Field(..., examples=[1])
    prefill: List[TextGenerationOutputPrefillToken]
    seed: Optional[conint(ge=0)] = Field(None, examples=[42])
    tokens: List[TextGenerationOutputToken]
    top_tokens: Optional[List[List[TextGenerationOutputToken]]] = None


class TextGenerationOutputDetails(BaseModel):
    best_of_sequences: Optional[List[TextGenerationOutputBestOfSequence]] = None
    finish_reason: TextGenerationOutputFinishReason
    generated_tokens: conint(ge=0) = Field(..., examples=[1])
    prefill: List[TextGenerationOutputPrefillToken]
    seed: Optional[conint(ge=0)] = Field(None, examples=[42])
    tokens: List[TextGenerationOutputToken]
    top_tokens: Optional[List[List[TextGenerationOutputToken]]] = None


class TextGenerationOutput(BaseModel):
    details: Optional[TextGenerationOutputDetails] = None
    generated_text: str = Field(..., examples=["test"])
