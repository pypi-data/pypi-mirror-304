[py-concodese]
# the path that contains grammars (e.g. the folder that contains "tree-sitter-c-master")
# If you don't have a grammar fplder, Set up an empty folder here and Pyconcodese will download the grammars from Github
grammar_path = "$grammars_path"

# the next 3 can be the root directory of the application if you wish (e.g.)
# the directory that you would like to store the sqlite database(s) in
sqlite_path = "$project_path"
# the directory that you would like to store the vsm data folders in
vsm_path = "$project_path"
# where to store output files generated by the application
output_path = "$project_path"

derby_path = "$derby_path"

# save results to csv
save_summary = false
save_full_results = false

[tokenization]
# whether to use jim for tokenization instead of tree sitter and INTT combo
use_jim = false

[dataset]
# absolute paths preferred over relative.
# path of bug repository file
bug_repository_file = "$bug_repository_file"
# path to source files (should include trailing / if bug report "fixed files" use relative paths)
src_path = "$project_path"
# src code languages to tokenize (can comment out as appropriate)
src_languages = [
  "rust",
  "java",
  "c#",
  "php",
]

[scoring]
# whether to use the alternative lex sim scoring class.
alt_lex_sim = false

[bug_reports]
# should duplicate terms be scored in both lex sim and vsm
score_duplicate_terms = false
minimum_term_length = 3
# Use spacy instead of Lucene
use_spacy = true

[vsm]
# index duplicate source file terms in vsm documents
index_duplicate_terms = true
# greatly increases loading time but is useful for testing multiple scoring configs
# only useful if the same bug report is going to be analysed more than once and all bug reports will be scored
precache_ranks = false

[misc]
# 1 or None will disable multi threading. 0 will use all but one of the detectable cores
processes = 6
