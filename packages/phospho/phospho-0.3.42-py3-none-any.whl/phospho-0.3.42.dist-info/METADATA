Metadata-Version: 2.1
Name: phospho
Version: 0.3.42
Summary: Text Analytics for LLM apps
Home-page: https://github.com/phospho-app/phospho
Keywords: LLM,Agents,gen ai,phospho,analytics,nlp
Author: phospho
Author-email: contact@phospho.ai
Requires-Python: >=3.9,<4.0
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Provides-Extra: lab
Requires-Dist: openai (>=1.12.0,<2.0.0) ; extra == "lab"
Requires-Dist: pandas (>=2.0.3,<3.0.0) ; extra == "lab"
Requires-Dist: pydantic (>=2.5.2,<3.0.0)
Requires-Dist: requests (>=2.32.3,<3.0.0)
Requires-Dist: rich (>=13.7.1,<14.0.0)
Requires-Dist: tiktoken (>=0.8.0,<0.9.0) ; extra == "lab"
Requires-Dist: tqdm (>=4.66.2,<5.0.0)
Requires-Dist: typer[all] (>=0.6)
Project-URL: Documentation, https://docs.phospho.ai
Description-Content-Type: text/markdown

# phospho Python Client

Phospho is an open source platform to help you monitor LLM apps.

With phospho, monitor every user interaction with your LLM app to identify issues and improve performance. Understand how users use your app and which versions of your product are the most successful.

Read the docs at [docs.phospho.ai](https://docs.phospho.ai/).

> _Warning_ : This project is still under active development!

## Installation of the phospho client

You need Python `>=3.9`

```bash
pip install --upgrade phospho
```

## Quickstart

Create an account on [phospho](https://platform.phospho.ai/). Create an API key and note down the project id. Set them as environment variables:

```bash
export PHOSPHO_API_KEY="your-api-key"
export PHOSPHO_PROJECT_ID="project-id"
```

In the code of your LLM app, log interactions with your agent using `phospho.log()`.

```python
import phospho

phospho.init()

# This is how you log interactions to phospho as strings
phospho.log(input="The user input", output="Your LLM app output")

```

You can also directly pass OpenAI API query and responses (or any object with same format) to phospho :

```python
import phospho
import openai

phospho.init()
openai_client = openai.OpenAI()

# This is your agent code
query = {
    "messages": [{"role": "user", "content": "The user input"}],
    "model": "gpt-3.5-turbo",
}
response = openai_client.chat.completions.create(**query)

# Log the interactions to phospho
phospho.log(input=query, output=response)
```

Monitor and visualize your agent on the [phospho dashboard](https://platform.phospho.ai/).

## phospho lab

You can also use phospho locally to run evaluations and event detection on your text messages.
See the [phospho lab documentation](https://docs.phospho.ai/local/phospho-lab) for more information or the notebook `quicksart.ipynb` in the `notebooks` folder.

## Usage

Read the docs at [docs.phospho.ai](https://docs.phospho.ai/) for more information.
Use your phospho dashboard to monitor your agent, score interactions and detect events.

